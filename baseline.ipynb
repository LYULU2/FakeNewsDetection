{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "InFaZfhGY8Xl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc70a29-2cc5-4ae5-e6f9-5c25ab481eee"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vj2-viVHXgC"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6CzDrqYgCe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d20ce8-ab3e-4475-faa0-2d4f852c13b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_KnwD9wkdmV"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout\n",
        "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.callbacks import History\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGfWT9Vo8Cy_"
      },
      "source": [
        "fake = pd.read_csv('/content/drive/My Drive/data/Fake.csv', delimiter = ',')\n",
        "true = pd.read_csv('/content/drive/My Drive/data/True.csv', delimiter = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoJbELx9Khfp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a3ec33f8-0b90-490c-cdaa-00f89c7761d3"
      },
      "source": [
        "fake_and_true = pd.read_csv('/content/drive/My Drive/data/fake_or_real_news.csv', delimiter=',')\n",
        "fake_and_true.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8476</td>\n",
              "      <td>You Can Smell Hillary’s Fear</td>\n",
              "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10294</td>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3608</td>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
              "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10142</td>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>875</td>\n",
              "      <td>The Battle of New York: Why This Primary Matters</td>\n",
              "      <td>It's primary day in New York and front-runners...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... label\n",
              "0        8476  ...  FAKE\n",
              "1       10294  ...  FAKE\n",
              "2        3608  ...  REAL\n",
              "3       10142  ...  FAKE\n",
              "4         875  ...  REAL\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsWg8gYoMBN5"
      },
      "source": [
        "fake_and_true[\"text\"] = fake_and_true[\"title\"] + \" \" + fake_and_true[\"text\"]\n",
        "\n",
        "fake_and_true.loc[fake_and_true[\"label\"]=='FAKE',\"label\"] = 0\n",
        "fake_and_true.loc[fake_and_true[\"label\"]=='REAL',\"label\"]= 1\n",
        "fake_and_true.drop(columns= ['title','Unnamed: 0'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsDKO0IT8Lkq"
      },
      "source": [
        "fake['label']= 0\n",
        "true['label']= 1\n",
        "\n",
        "dataset =pd.DataFrame()\n",
        "dataset = true.append(fake)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AWwcT6PNfHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a972b3f-ad10-49d8-b3cb-72523be1ee66"
      },
      "source": [
        "fake_and_true.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0  You Can Smell Hillary’s Fear Daniel Greenfield...     0\n",
              "1  Watch The Exact Moment Paul Ryan Committed Pol...     0\n",
              "2  Kerry to go to Paris in gesture of sympathy U....     1\n",
              "3  Bernie supporters on Twitter erupt in anger ag...     0\n",
              "4  The Battle of New York: Why This Primary Matte...     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRfUfST486aw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cd08ad32-84d8-4a77-da00-2dd3b32ea82c"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
              "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U.S. military to accept transgender recruits o...</td>\n",
              "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
              "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
              "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
              "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ... label\n",
              "0  As U.S. budget fight looms, Republicans flip t...  ...     1\n",
              "1  U.S. military to accept transgender recruits o...  ...     1\n",
              "2  Senior U.S. Republican senator: 'Let Mr. Muell...  ...     1\n",
              "3  FBI Russia probe helped by Australian diplomat...  ...     1\n",
              "4  Trump wants Postal Service to charge 'much mor...  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IIStIJ78_re",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566150b2-2d00-417f-f083-723723afa462"
      },
      "source": [
        "dataset[\"text\"] = dataset[\"title\"] + \" \" + dataset[\"text\"]\n",
        "dataset.drop(columns= ['title','subject', 'date'], inplace=True)\n",
        "\n",
        "dataset = pd.concat([fake_and_true, dataset], ignore_index=True)\n",
        "dataset.info"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of                                                     text label\n",
              "0      You Can Smell Hillary’s Fear Daniel Greenfield...     0\n",
              "1      Watch The Exact Moment Paul Ryan Committed Pol...     0\n",
              "2      Kerry to go to Paris in gesture of sympathy U....     1\n",
              "3      Bernie supporters on Twitter erupt in anger ag...     0\n",
              "4      The Battle of New York: Why This Primary Matte...     1\n",
              "...                                                  ...   ...\n",
              "51228  McPain: John McCain Furious That Iran Treated ...     0\n",
              "51229  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...     0\n",
              "51230  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...     0\n",
              "51231  How to Blow $700 Million: Al Jazeera America F...     0\n",
              "51232  10 U.S. Navy Sailors Held by Iranian Military ...     0\n",
              "\n",
              "[51233 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9B2j_vQB19w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5bb692d9-1f88-4b1f-d792-ba6605c2b9a2"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0  You Can Smell Hillary’s Fear Daniel Greenfield...     0\n",
              "1  Watch The Exact Moment Paul Ryan Committed Pol...     0\n",
              "2  Kerry to go to Paris in gesture of sympathy U....     1\n",
              "3  Bernie supporters on Twitter erupt in anger ag...     0\n",
              "4  The Battle of New York: Why This Primary Matte...     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s7-rrrTV13E"
      },
      "source": [
        "dataset['label'] = dataset['label'].astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOPyDGRsLzR8"
      },
      "source": [
        "### clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh9GIwcF-Asz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "136271e4-15f8-4b9b-c803-c5785926d81b"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('wordnet')\n",
        "porter_stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "stemmed_text = []\n",
        "lemmatized_text = []\n",
        "for text in dataset['text']:\n",
        "    result = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    result = result.lower()\n",
        "    result = result.split()\n",
        "    result = [r for r in result if r not in set(stopwords.words('english'))]\n",
        "    stemmed_result = [porter_stemmer.stem(r) for r in result]\n",
        "    stemmed_text.append(\" \".join(stemmed_result))\n",
        "    lemmatized_result = [lemmatizer.lemmatize(r) for r in result]\n",
        "    lemmatized_text.append(\" \".join(lemmatized_result))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMoY4QWLknB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2066653-3a41-4ccc-8c6e-52eddbcbf9df"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "stemmed_text = []\n",
        "for text in dataset['text']:\n",
        "    result = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    result = result.lower()\n",
        "    result = result.split()\n",
        "    result = [r for r in result if r not in set(stopwords.words('english'))]\n",
        "    stemmed_result = [porter_stemmer.stem(r) for r in result]\n",
        "    stemmed_text.append(\" \".join(stemmed_result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5cNXF4wZuS0"
      },
      "source": [
        "## pipeline for selecting classifier and text feature extractor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Dj3g21NeQE"
      },
      "source": [
        "def get_prediction(vectorizer, classifier, X_train, X_test, y_train, y_test):\n",
        "    pipe = Pipeline([('vector', vectorizer),\n",
        "                    ('model', classifier)])\n",
        "    model = pipe.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"Accuarcy: {}\".format(round(accuracy_score(y_test, y_pred)*100,2)))\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix: \\n\", cm)\n",
        "    print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rztu1ZiIT8AF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b769f3-6706-4aba-b642-bfe7db389775"
      },
      "source": [
        "print(len(stemmed_text))\n",
        "print(len(lemmatized_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51233\n",
            "51233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSHBTtuVRy2h"
      },
      "source": [
        "### use stemmed text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuZiBT3ZZ6Wr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ecf3125-2836-430e-8d52-76b7e66e8494"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(stemmed_text, dataset['label'], test_size = 0.3, random_state= 42)\n",
        "classifiers = [LogisticRegression(), SGDClassifier(), MultinomialNB(), BernoulliNB(), LinearSVC(),\n",
        "              KNeighborsClassifier(n_neighbors=5), DecisionTreeClassifier(), GradientBoostingClassifier(), \n",
        "               RandomForestClassifier(), XGBClassifier()]\n",
        "for classifier in classifiers:\n",
        "    print(\"\\n\\n\", classifier)\n",
        "    print(\"***********Usng Count Vectorizer****************\")\n",
        "    get_prediction(CountVectorizer(), classifier, X_train, X_test, y_train, y_test)\n",
        "    print(\"***********Usng TFIDF Vectorizer****************\")\n",
        "    get_prediction(TfidfVectorizer(), classifier, X_train, X_test, y_train, y_test)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "***********Usng Count Vectorizer****************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuarcy: 97.49\n",
            "Confusion Matrix: \n",
            " [[7847  155]\n",
            " [ 231 7137]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      8002\n",
            "           1       0.98      0.97      0.97      7368\n",
            "\n",
            "    accuracy                           0.97     15370\n",
            "   macro avg       0.98      0.97      0.97     15370\n",
            "weighted avg       0.97      0.97      0.97     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 96.43\n",
            "Confusion Matrix: \n",
            " [[7780  222]\n",
            " [ 326 7042]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      8002\n",
            "           1       0.97      0.96      0.96      7368\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "\n",
            "\n",
            " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
            "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
            "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
            "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 96.94\n",
            "Confusion Matrix: \n",
            " [[7840  162]\n",
            " [ 308 7060]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      8002\n",
            "           1       0.98      0.96      0.97      7368\n",
            "\n",
            "    accuracy                           0.97     15370\n",
            "   macro avg       0.97      0.97      0.97     15370\n",
            "weighted avg       0.97      0.97      0.97     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 96.71\n",
            "Confusion Matrix: \n",
            " [[7825  177]\n",
            " [ 328 7040]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      8002\n",
            "           1       0.98      0.96      0.97      7368\n",
            "\n",
            "    accuracy                           0.97     15370\n",
            "   macro avg       0.97      0.97      0.97     15370\n",
            "weighted avg       0.97      0.97      0.97     15370\n",
            "\n",
            "\n",
            "\n",
            " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 92.19\n",
            "Confusion Matrix: \n",
            " [[7404  598]\n",
            " [ 602 6766]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.93      8002\n",
            "           1       0.92      0.92      0.92      7368\n",
            "\n",
            "    accuracy                           0.92     15370\n",
            "   macro avg       0.92      0.92      0.92     15370\n",
            "weighted avg       0.92      0.92      0.92     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 90.36\n",
            "Confusion Matrix: \n",
            " [[7360  642]\n",
            " [ 840 6528]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91      8002\n",
            "           1       0.91      0.89      0.90      7368\n",
            "\n",
            "    accuracy                           0.90     15370\n",
            "   macro avg       0.90      0.90      0.90     15370\n",
            "weighted avg       0.90      0.90      0.90     15370\n",
            "\n",
            "\n",
            "\n",
            " BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 92.93\n",
            "Confusion Matrix: \n",
            " [[7464  538]\n",
            " [ 548 6820]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      8002\n",
            "           1       0.93      0.93      0.93      7368\n",
            "\n",
            "    accuracy                           0.93     15370\n",
            "   macro avg       0.93      0.93      0.93     15370\n",
            "weighted avg       0.93      0.93      0.93     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 92.93\n",
            "Confusion Matrix: \n",
            " [[7464  538]\n",
            " [ 548 6820]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      8002\n",
            "           1       0.93      0.93      0.93      7368\n",
            "\n",
            "    accuracy                           0.93     15370\n",
            "   macro avg       0.93      0.93      0.93     15370\n",
            "weighted avg       0.93      0.93      0.93     15370\n",
            "\n",
            "\n",
            "\n",
            " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "          verbose=0)\n",
            "***********Usng Count Vectorizer****************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuarcy: 96.66\n",
            "Confusion Matrix: \n",
            " [[7787  215]\n",
            " [ 298 7070]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      8002\n",
            "           1       0.97      0.96      0.96      7368\n",
            "\n",
            "    accuracy                           0.97     15370\n",
            "   macro avg       0.97      0.97      0.97     15370\n",
            "weighted avg       0.97      0.97      0.97     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 97.81\n",
            "Confusion Matrix: \n",
            " [[7872  130]\n",
            " [ 206 7162]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      8002\n",
            "           1       0.98      0.97      0.98      7368\n",
            "\n",
            "    accuracy                           0.98     15370\n",
            "   macro avg       0.98      0.98      0.98     15370\n",
            "weighted avg       0.98      0.98      0.98     15370\n",
            "\n",
            "\n",
            "\n",
            " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 78.79\n",
            "Confusion Matrix: \n",
            " [[6417 1585]\n",
            " [1675 5693]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.80      0.80      8002\n",
            "           1       0.78      0.77      0.78      7368\n",
            "\n",
            "    accuracy                           0.79     15370\n",
            "   macro avg       0.79      0.79      0.79     15370\n",
            "weighted avg       0.79      0.79      0.79     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 83.65\n",
            "Confusion Matrix: \n",
            " [[6055 1947]\n",
            " [ 566 6802]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.76      0.83      8002\n",
            "           1       0.78      0.92      0.84      7368\n",
            "\n",
            "    accuracy                           0.84     15370\n",
            "   macro avg       0.85      0.84      0.84     15370\n",
            "weighted avg       0.85      0.84      0.84     15370\n",
            "\n",
            "\n",
            "\n",
            " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 95.65\n",
            "Confusion Matrix: \n",
            " [[7713  289]\n",
            " [ 380 6988]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96      8002\n",
            "           1       0.96      0.95      0.95      7368\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 95.26\n",
            "Confusion Matrix: \n",
            " [[7708  294]\n",
            " [ 434 6934]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95      8002\n",
            "           1       0.96      0.94      0.95      7368\n",
            "\n",
            "    accuracy                           0.95     15370\n",
            "   macro avg       0.95      0.95      0.95     15370\n",
            "weighted avg       0.95      0.95      0.95     15370\n",
            "\n",
            "\n",
            "\n",
            " GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 96.04\n",
            "Confusion Matrix: \n",
            " [[7863  139]\n",
            " [ 469 6899]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96      8002\n",
            "           1       0.98      0.94      0.96      7368\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 96.2\n",
            "Confusion Matrix: \n",
            " [[7870  132]\n",
            " [ 452 6916]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96      8002\n",
            "           1       0.98      0.94      0.96      7368\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "\n",
            "\n",
            " RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 95.79\n",
            "Confusion Matrix: \n",
            " [[7802  200]\n",
            " [ 447 6921]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96      8002\n",
            "           1       0.97      0.94      0.96      7368\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 95.83\n",
            "Confusion Matrix: \n",
            " [[7810  192]\n",
            " [ 449 6919]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96      8002\n",
            "           1       0.97      0.94      0.96      7368\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "\n",
            "\n",
            " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 96.15\n",
            "Confusion Matrix: \n",
            " [[7857  145]\n",
            " [ 447 6921]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96      8002\n",
            "           1       0.98      0.94      0.96      7368\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 96.23\n",
            "Confusion Matrix: \n",
            " [[7868  134]\n",
            " [ 446 6922]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96      8002\n",
            "           1       0.98      0.94      0.96      7368\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYjUHqfbRp4j"
      },
      "source": [
        "### use lemmatized text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOpCNkU5uMsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebfe0f87-7493-44f0-9008-1a41c4bed2cb"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(lemmatized_text, dataset['label'], test_size = 0.3, random_state= 0)\n",
        "classifiers = [LogisticRegression(), SGDClassifier(), MultinomialNB(), BernoulliNB(), LinearSVC(),\n",
        "              KNeighborsClassifier(n_neighbors=5), DecisionTreeClassifier(), GradientBoostingClassifier(), \n",
        "               RandomForestClassifier(), XGBClassifier()]\n",
        "for classifier in classifiers:\n",
        "    print(\"\\n\\n\", classifier)\n",
        "    print(\"***********Usng Count Vectorizer****************\")\n",
        "    get_prediction(CountVectorizer(), classifier, X_train, X_test, y_train, y_test)\n",
        "    print(\"***********Usng TFIDF Vectorizer****************\")\n",
        "    get_prediction(TfidfVectorizer(), classifier, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "***********Usng Count Vectorizer****************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuarcy: 97.46\n",
            "Confusion Matrix: \n",
            " [[7814  163]\n",
            " [ 228 7165]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      7977\n",
            "           1       0.98      0.97      0.97      7393\n",
            "\n",
            "    accuracy                           0.97     15370\n",
            "   macro avg       0.97      0.97      0.97     15370\n",
            "weighted avg       0.97      0.97      0.97     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 96.47\n",
            "Confusion Matrix: \n",
            " [[7734  243]\n",
            " [ 300 7093]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      7977\n",
            "           1       0.97      0.96      0.96      7393\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "\n",
            "\n",
            " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
            "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
            "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
            "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 96.86\n",
            "Confusion Matrix: \n",
            " [[7785  192]\n",
            " [ 291 7102]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      7977\n",
            "           1       0.97      0.96      0.97      7393\n",
            "\n",
            "    accuracy                           0.97     15370\n",
            "   macro avg       0.97      0.97      0.97     15370\n",
            "weighted avg       0.97      0.97      0.97     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 96.73\n",
            "Confusion Matrix: \n",
            " [[7766  211]\n",
            " [ 291 7102]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      7977\n",
            "           1       0.97      0.96      0.97      7393\n",
            "\n",
            "    accuracy                           0.97     15370\n",
            "   macro avg       0.97      0.97      0.97     15370\n",
            "weighted avg       0.97      0.97      0.97     15370\n",
            "\n",
            "\n",
            "\n",
            " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 92.49\n",
            "Confusion Matrix: \n",
            " [[7380  597]\n",
            " [ 557 6836]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      7977\n",
            "           1       0.92      0.92      0.92      7393\n",
            "\n",
            "    accuracy                           0.92     15370\n",
            "   macro avg       0.92      0.92      0.92     15370\n",
            "weighted avg       0.92      0.92      0.92     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 90.81\n",
            "Confusion Matrix: \n",
            " [[7323  654]\n",
            " [ 759 6634]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.91      7977\n",
            "           1       0.91      0.90      0.90      7393\n",
            "\n",
            "    accuracy                           0.91     15370\n",
            "   macro avg       0.91      0.91      0.91     15370\n",
            "weighted avg       0.91      0.91      0.91     15370\n",
            "\n",
            "\n",
            "\n",
            " BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 93.01\n",
            "Confusion Matrix: \n",
            " [[7452  525]\n",
            " [ 550 6843]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      7977\n",
            "           1       0.93      0.93      0.93      7393\n",
            "\n",
            "    accuracy                           0.93     15370\n",
            "   macro avg       0.93      0.93      0.93     15370\n",
            "weighted avg       0.93      0.93      0.93     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 93.01\n",
            "Confusion Matrix: \n",
            " [[7452  525]\n",
            " [ 550 6843]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      7977\n",
            "           1       0.93      0.93      0.93      7393\n",
            "\n",
            "    accuracy                           0.93     15370\n",
            "   macro avg       0.93      0.93      0.93     15370\n",
            "weighted avg       0.93      0.93      0.93     15370\n",
            "\n",
            "\n",
            "\n",
            " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "          verbose=0)\n",
            "***********Usng Count Vectorizer****************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuarcy: 96.81\n",
            "Confusion Matrix: \n",
            " [[7768  209]\n",
            " [ 281 7112]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      7977\n",
            "           1       0.97      0.96      0.97      7393\n",
            "\n",
            "    accuracy                           0.97     15370\n",
            "   macro avg       0.97      0.97      0.97     15370\n",
            "weighted avg       0.97      0.97      0.97     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 97.62\n",
            "Confusion Matrix: \n",
            " [[7822  155]\n",
            " [ 211 7182]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      7977\n",
            "           1       0.98      0.97      0.98      7393\n",
            "\n",
            "    accuracy                           0.98     15370\n",
            "   macro avg       0.98      0.98      0.98     15370\n",
            "weighted avg       0.98      0.98      0.98     15370\n",
            "\n",
            "\n",
            "\n",
            " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 77.9\n",
            "Confusion Matrix: \n",
            " [[6482 1495]\n",
            " [1902 5491]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.81      0.79      7977\n",
            "           1       0.79      0.74      0.76      7393\n",
            "\n",
            "    accuracy                           0.78     15370\n",
            "   macro avg       0.78      0.78      0.78     15370\n",
            "weighted avg       0.78      0.78      0.78     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 84.42\n",
            "Confusion Matrix: \n",
            " [[6113 1864]\n",
            " [ 531 6862]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.77      0.84      7977\n",
            "           1       0.79      0.93      0.85      7393\n",
            "\n",
            "    accuracy                           0.84     15370\n",
            "   macro avg       0.85      0.85      0.84     15370\n",
            "weighted avg       0.86      0.84      0.84     15370\n",
            "\n",
            "\n",
            "\n",
            " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 95.93\n",
            "Confusion Matrix: \n",
            " [[7689  288]\n",
            " [ 338 7055]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96      7977\n",
            "           1       0.96      0.95      0.96      7393\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 95.54\n",
            "Confusion Matrix: \n",
            " [[7680  297]\n",
            " [ 388 7005]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96      7977\n",
            "           1       0.96      0.95      0.95      7393\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "\n",
            "\n",
            " GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 96.36\n",
            "Confusion Matrix: \n",
            " [[7840  137]\n",
            " [ 422 6971]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97      7977\n",
            "           1       0.98      0.94      0.96      7393\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 96.42\n",
            "Confusion Matrix: \n",
            " [[7845  132]\n",
            " [ 418 6975]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97      7977\n",
            "           1       0.98      0.94      0.96      7393\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.97      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "\n",
            "\n",
            " RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 95.87\n",
            "Confusion Matrix: \n",
            " [[7730  247]\n",
            " [ 388 7005]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96      7977\n",
            "           1       0.97      0.95      0.96      7393\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 95.84\n",
            "Confusion Matrix: \n",
            " [[7762  215]\n",
            " [ 424 6969]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96      7977\n",
            "           1       0.97      0.94      0.96      7393\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.96      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "\n",
            "\n",
            " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "***********Usng Count Vectorizer****************\n",
            "Accuarcy: 96.4\n",
            "Confusion Matrix: \n",
            " [[7847  130]\n",
            " [ 424 6969]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97      7977\n",
            "           1       0.98      0.94      0.96      7393\n",
            "\n",
            "    accuracy                           0.96     15370\n",
            "   macro avg       0.97      0.96      0.96     15370\n",
            "weighted avg       0.96      0.96      0.96     15370\n",
            "\n",
            "***********Usng TFIDF Vectorizer****************\n",
            "Accuarcy: 96.57\n",
            "Confusion Matrix: \n",
            " [[7860  117]\n",
            " [ 410 6983]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      7977\n",
            "           1       0.98      0.94      0.96      7393\n",
            "\n",
            "    accuracy                           0.97     15370\n",
            "   macro avg       0.97      0.96      0.97     15370\n",
            "weighted avg       0.97      0.97      0.97     15370\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZD70OzRgEYX"
      },
      "source": [
        "from above, we can see that stemmed text with KNeighborsClassifier gives the best accuracy: 97.81\n",
        "***********Usng TFIDF Vectorizer****************\n",
        "Accuarcy: 97.81\n",
        "Confusion Matrix: \n",
        " [[7872  130]\n",
        " [ 206 7162]]\n",
        "Classification Report: \n",
        "               precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      0.98      0.98      8002\n",
        "           1       0.98      0.97      0.98      7368\n",
        "\n",
        "    accuracy                           0.98     15370\n",
        "   macro avg       0.98      0.98      0.98     15370\n",
        "weighted avg       0.98      0.98      0.98     15370\n",
        "\n",
        "\n",
        "\n",
        " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
        "                     weights='uniform')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUIbuAqqTbXQ"
      },
      "source": [
        "## pipeline for hyper parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfBLdB0MTZ92"
      },
      "source": [
        "from pprint import pprint\n",
        "from time import time\n",
        "import logging\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw2aLf_xUOrk"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    #('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', KNeighborsClassifier()),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-2BFCyYYJon"
      },
      "source": [
        "parameters = {\n",
        "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
        "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
        "    #'vect__ngram_range': ((1, 1), (2, 2)),\n",
        "    #'tfidf__use_idf': (True, False),\n",
        "    'tfidf__norm': ('l1', 'l2'),\n",
        "    'clf__leaf_size': (20, 30, 50),\n",
        "    'clf__n_neighbors': list(range(2,8,2)),\n",
        "    #'clf__p': (1,2),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uPBM6OVYj7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96dde941-bfdd-4451-da36-53efa9338973"
      },
      "source": [
        "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
        "\n",
        "print(\"Performing grid search...\")\n",
        "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
        "print(\"parameters:\")\n",
        "pprint(parameters)\n",
        "t0 = time()\n",
        "grid_search.fit(stemmed_text, dataset['label'])\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print()\n",
        "\n",
        "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = grid_search.best_estimator_.get_params()\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['tfidf', 'clf']\n",
            "parameters:\n",
            "{'clf__leaf_size': (20, 30, 50),\n",
            " 'clf__n_neighbors': [2, 4, 6],\n",
            " 'tfidf__norm': ('l1', 'l2')}\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 25.2min\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed: 49.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done in 2972.196s\n",
            "\n",
            "Best score: 0.766\n",
            "Best parameters set:\n",
            "\tclf__leaf_size: 20\n",
            "\tclf__n_neighbors: 2\n",
            "\ttfidf__norm: 'l2'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkMXopzEkQyo"
      },
      "source": [
        "get_prediction(TfidfVectorizer(norm = 'l2'), KNeighborsClassifier(leaf_size = 20, n_neighbor), X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}