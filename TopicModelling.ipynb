{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TopicModelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LYULU2/FakeNewsDetection/blob/main/TopicModelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjAwENS1pN7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44992faf-cd89-4002-eabe-994e0d00b55a"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEYeVjhClPZ_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from gensim import matutils, models\n",
        "import scipy.sparse\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtmbpqTxlSUO"
      },
      "source": [
        "def process_text(text):\n",
        "    combined = ' '.join(text)\n",
        "    return combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GGmQOgAlTrs",
        "outputId": "c9a126f2-9e6a-4e07-9d1c-572c038d487e"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def clean_text(text):\n",
        "  stemmed_text = []\n",
        "  porter_stemmer = PorterStemmer()\n",
        "  text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "  text = re.sub(r'http\\S+', '', text)\n",
        "  text = re.sub(r'www\\.[a-z]+\\.at', '', text)\n",
        "  result = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "  result = result.lower()\n",
        "  result = result.split()\n",
        "  result = [r for r in result if r not in set(stopwords.words('english'))]\n",
        "  stemmed_result = [porter_stemmer.stem(r) for r in result]\n",
        "  stemmed_text.append(\" \".join(stemmed_result))\n",
        "  return stemmed_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWjvi4vvkhVS",
        "outputId": "78607a66-bbb6-4a72-94a9-e79ec11e6eaa"
      },
      "source": [
        "data_alt_before = pd.read_csv('/content/drive/MyDrive/Alt-right-2018-01-01--2020-02-29.csv', delimiter=',')\n",
        "data_anti_before = pd.read_csv('/content/drive/MyDrive/AVaxxer-2018-01-01--2020-02-29.csv', delimiter=',')\n",
        "data_alt_after = pd.read_csv('/content/drive/MyDrive/Alt-right-2020-03-01--2021-09-19.csv', delimiter=',')\n",
        "data_anti_after = pd.read_csv('/content/drive/MyDrive/AVaxxer-2020-03-01--2021-09-19.csv', delimiter=',')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (37,38,39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "xAmK6zRhloTp",
        "outputId": "61a4f903-587d-445a-e957-44d76fcc3d8c"
      },
      "source": [
        "data_alt_before.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Page Name</th>\n",
              "      <th>User Name</th>\n",
              "      <th>Facebook Id</th>\n",
              "      <th>Page Category</th>\n",
              "      <th>Page Admin Top Country</th>\n",
              "      <th>Page Description</th>\n",
              "      <th>Page Created</th>\n",
              "      <th>Likes at Posting</th>\n",
              "      <th>Followers at Posting</th>\n",
              "      <th>Post Created</th>\n",
              "      <th>Post Created Date</th>\n",
              "      <th>Post Created Time</th>\n",
              "      <th>Type</th>\n",
              "      <th>Total Interactions</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Shares</th>\n",
              "      <th>Love</th>\n",
              "      <th>Wow</th>\n",
              "      <th>Haha</th>\n",
              "      <th>Sad</th>\n",
              "      <th>Angry</th>\n",
              "      <th>Care</th>\n",
              "      <th>Video Share Status</th>\n",
              "      <th>Is Video Owner?</th>\n",
              "      <th>Post Views</th>\n",
              "      <th>Total Views</th>\n",
              "      <th>Total Views For All Crossposts</th>\n",
              "      <th>Video Length</th>\n",
              "      <th>URL</th>\n",
              "      <th>Message</th>\n",
              "      <th>Link</th>\n",
              "      <th>Final Link</th>\n",
              "      <th>Image Text</th>\n",
              "      <th>Link Text</th>\n",
              "      <th>Description</th>\n",
              "      <th>Sponsor Id</th>\n",
              "      <th>Sponsor Name</th>\n",
              "      <th>Sponsor Category</th>\n",
              "      <th>Overperforming Score (weighted  â€”  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Conservative</td>\n",
              "      <td>the.conservative2</td>\n",
              "      <td>605636446121211</td>\n",
              "      <td>MEDIA_NEWS_COMPANY</td>\n",
              "      <td>US</td>\n",
              "      <td>\"They who can give up essential liberty to obt...</td>\n",
              "      <td>2013-06-05 21:30:50</td>\n",
              "      <td>209150.0</td>\n",
              "      <td>192427.0</td>\n",
              "      <td>2020-02-28 19:02:03 PST</td>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>19:02:03</td>\n",
              "      <td>Link</td>\n",
              "      <td>18</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.facebook.com/605636446121211/posts...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://dlvr.it/RQyPhP</td>\n",
              "      <td>https://www.dailywire.com/news/aoc-rips-pence-...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AOC Rips Pence As â€˜Anti-Science.â€™ Cruz Shreds ...</td>\n",
              "      <td>When President Donald Trump announced Wednesda...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Republican Security Council</td>\n",
              "      <td>RSC.GOP</td>\n",
              "      <td>101173139981866</td>\n",
              "      <td>POLITICAL_PARTY</td>\n",
              "      <td>US</td>\n",
              "      <td>We are part of the GOP's national security win...</td>\n",
              "      <td>2011-07-12 21:47:03</td>\n",
              "      <td>105681.0</td>\n",
              "      <td>105770.0</td>\n",
              "      <td>2020-02-28 18:59:24 PST</td>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>18:59:24</td>\n",
              "      <td>Photo</td>\n",
              "      <td>3,366</td>\n",
              "      <td>1531</td>\n",
              "      <td>115</td>\n",
              "      <td>1138</td>\n",
              "      <td>479</td>\n",
              "      <td>99</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.facebook.com/101173139981866/posts...</td>\n",
              "      <td>Happy Birthday To Madeleine Carroll. She Was T...</td>\n",
              "      <td>https://www.facebook.com/RSC.GOP/photos/a.1095...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Texas for Donald Trump 2020</td>\n",
              "      <td>Texasfordonaldtrump2020</td>\n",
              "      <td>869110696505336</td>\n",
              "      <td>FAN_PAGE</td>\n",
              "      <td>US</td>\n",
              "      <td>Disclaimer: This page is owned by a private US...</td>\n",
              "      <td>2015-08-18 21:02:41</td>\n",
              "      <td>296505.0</td>\n",
              "      <td>295158.0</td>\n",
              "      <td>2020-02-28 17:40:04 PST</td>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>17:40:04</td>\n",
              "      <td>Link</td>\n",
              "      <td>3,378</td>\n",
              "      <td>595</td>\n",
              "      <td>148</td>\n",
              "      <td>2011</td>\n",
              "      <td>9</td>\n",
              "      <td>154</td>\n",
              "      <td>5</td>\n",
              "      <td>39</td>\n",
              "      <td>417</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.facebook.com/869110696505336/posts...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://pjmedia.com/trending/fact-check-obama-...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fact-Check: Obama Waited Until 'Millions' Infe...</td>\n",
              "      <td>\"Let's call it Trumpvirus,\" urged a New York T...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>United Deplorables Of America</td>\n",
              "      <td>UnitedDeplorablesOfAmerica</td>\n",
              "      <td>427436237618707</td>\n",
              "      <td>ACTIVITY_GENERAL</td>\n",
              "      <td>US</td>\n",
              "      <td>We Are Trump's Deplorables and Together We Wil...</td>\n",
              "      <td>2017-04-12 04:47:02</td>\n",
              "      <td>328707.0</td>\n",
              "      <td>334862.0</td>\n",
              "      <td>2020-02-28 16:59:45 PST</td>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>16:59:45</td>\n",
              "      <td>Link</td>\n",
              "      <td>1,234</td>\n",
              "      <td>226</td>\n",
              "      <td>281</td>\n",
              "      <td>227</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>131</td>\n",
              "      <td>33</td>\n",
              "      <td>300</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.facebook.com/427436237618707/posts...</td>\n",
              "      <td>Pelosi Has Absolutely Lost Her Mind! ðŸ˜²ðŸ˜’</td>\n",
              "      <td>https://breakingfirst.com/nancy-pelosis-sanity...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Nancy Pelosiâ€™s Sanity &amp; Integrity Questioned A...</td>\n",
              "      <td>Democratic House Speaker Nancy Pelosi canâ€™t se...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Colorado for Donald Trump 2020</td>\n",
              "      <td>Colorado4DonaldTrump</td>\n",
              "      <td>1619236631661479</td>\n",
              "      <td>FAN_PAGE</td>\n",
              "      <td>US</td>\n",
              "      <td>Disclaimer: This page is owned by a private US...</td>\n",
              "      <td>2015-08-18 03:21:10</td>\n",
              "      <td>162575.0</td>\n",
              "      <td>159465.0</td>\n",
              "      <td>2020-02-28 06:00:59 PST</td>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>06:00:59</td>\n",
              "      <td>Native Video</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>share</td>\n",
              "      <td>No</td>\n",
              "      <td>671</td>\n",
              "      <td>619297</td>\n",
              "      <td>0</td>\n",
              "      <td>00:09:12</td>\n",
              "      <td>https://www.facebook.com/1619236631661479/post...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.facebook.com/FoxNews/videos/520705...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fox News</td>\n",
              "      <td>â€œWe have an opportunity to do exactly what the...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-4.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Page Name  ... Overperforming Score (weighted  â€”  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )\n",
              "0                The Conservative  ...                                              -2.67                                                                \n",
              "1     Republican Security Council  ...                                               3.07                                                                \n",
              "2     Texas for Donald Trump 2020  ...                                              20.98                                                                \n",
              "3   United Deplorables Of America  ...                                               1.54                                                                \n",
              "4  Colorado for Donald Trump 2020  ...                                              -4.25                                                                \n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6VC19qyuPxk"
      },
      "source": [
        "Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "wzwhhCl1lkpt",
        "outputId": "5436e204-f0c8-4725-92bf-397ae6eb6d3f"
      },
      "source": [
        "def pre_process(data):\n",
        "  data['Message'] = data['Message'].fillna('')\n",
        "  text = data['Message'].astype('string').tolist()\n",
        "  text_combined = process_text(text)\n",
        "  text_cleaned = clean_text(text_combined)\n",
        "  return text_cleaned\n",
        "\n",
        "alt_before = pre_process(data_alt_before)\n",
        "alt_after = pre_process(data_alt_after)\n",
        "anti_before = pre_process(data_anti_before)\n",
        "anti_after = pre_process(data_anti_after)\n",
        "\n",
        "combined_dict = {\"alt-before\":alt_before, \"anti-before\": anti_before,\"alt-after\":alt_after,\"anti-after\":anti_after}\n",
        "data_df = pd.DataFrame.from_dict(combined_dict, orient='index', columns=['text'])\n",
        "data_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>alt-before</th>\n",
              "      <td>happi birthday madelein carrol highest paid ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anti-before</th>\n",
              "      <td>realli gonna kill everybodi dmt spiritu scienc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alt-after</th>\n",
              "      <td>classifi testimoni opposit biden surrend under...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anti-after</th>\n",
              "      <td>see break fda panel overwhelmingli reject pfiz...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                          text\n",
              "alt-before   happi birthday madelein carrol highest paid ac...\n",
              "anti-before  realli gonna kill everybodi dmt spiritu scienc...\n",
              "alt-after    classifi testimoni opposit biden surrend under...\n",
              "anti-after   see break fda panel overwhelmingli reject pfiz..."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "e_MUTjbBhm2S",
        "outputId": "1ed0dbab-a619-4f64-b341-0bc466ddd31d"
      },
      "source": [
        "cv = CountVectorizer(stop_words='english')\n",
        "#cv = CountVectorizer()\n",
        "data_cv = cv.fit_transform(data_df.text)\n",
        "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
        "data_dtm.index = data_df.index\n",
        "data_dtm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>aaa</th>\n",
              "      <th>aaaaaaaab</th>\n",
              "      <th>aaaaaaand</th>\n",
              "      <th>aaaaand</th>\n",
              "      <th>aaaac</th>\n",
              "      <th>aaaand</th>\n",
              "      <th>aaaci</th>\n",
              "      <th>aaacnlkw</th>\n",
              "      <th>aaadb</th>\n",
              "      <th>aaadnnb</th>\n",
              "      <th>aaaexzhzq</th>\n",
              "      <th>aaagl</th>\n",
              "      <th>aaah</th>\n",
              "      <th>aaakxza</th>\n",
              "      <th>aaamp</th>\n",
              "      <th>aaand</th>\n",
              "      <th>aaap</th>\n",
              "      <th>aaargu</th>\n",
              "      <th>aab</th>\n",
              "      <th>aabg</th>\n",
              "      <th>aabi</th>\n",
              "      <th>aabot</th>\n",
              "      <th>aabydc</th>\n",
              "      <th>aac</th>\n",
              "      <th>aacd</th>\n",
              "      <th>aaceihti</th>\n",
              "      <th>aach</th>\n",
              "      <th>aacijourn</th>\n",
              "      <th>aaciw</th>\n",
              "      <th>aacjo</th>\n",
              "      <th>aacp</th>\n",
              "      <th>aacpl</th>\n",
              "      <th>aacr</th>\n",
              "      <th>aacspjemqhlt</th>\n",
              "      <th>aad</th>\n",
              "      <th>aadaenpt</th>\n",
              "      <th>aadb</th>\n",
              "      <th>aadewk</th>\n",
              "      <th>aadf</th>\n",
              "      <th>...</th>\n",
              "      <th>zzikieru</th>\n",
              "      <th>zzit</th>\n",
              "      <th>zzjv</th>\n",
              "      <th>zzjye</th>\n",
              "      <th>zzkinr</th>\n",
              "      <th>zzkp</th>\n",
              "      <th>zzkusmlj</th>\n",
              "      <th>zzl</th>\n",
              "      <th>zzm</th>\n",
              "      <th>zzmale</th>\n",
              "      <th>zzmit</th>\n",
              "      <th>zzn</th>\n",
              "      <th>zzo</th>\n",
              "      <th>zzon</th>\n",
              "      <th>zzp</th>\n",
              "      <th>zzpb</th>\n",
              "      <th>zzqh</th>\n",
              "      <th>zzqxi</th>\n",
              "      <th>zzr</th>\n",
              "      <th>zzrom</th>\n",
              "      <th>zzsn</th>\n",
              "      <th>zzsqif</th>\n",
              "      <th>zzsvhqga</th>\n",
              "      <th>zztiyhtu</th>\n",
              "      <th>zztn</th>\n",
              "      <th>zztopmloweyfjgiyi</th>\n",
              "      <th>zzu</th>\n",
              "      <th>zzuk</th>\n",
              "      <th>zzuusn</th>\n",
              "      <th>zzvhpw</th>\n",
              "      <th>zzvptbxqh</th>\n",
              "      <th>zzw</th>\n",
              "      <th>zzwqlk</th>\n",
              "      <th>zzwyiek</th>\n",
              "      <th>zzxaepj</th>\n",
              "      <th>zzxtcm</th>\n",
              "      <th>zzxtftzr</th>\n",
              "      <th>zzybvuyyao</th>\n",
              "      <th>zzzivafq</th>\n",
              "      <th>zzzvlmcp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>alt-before</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anti-before</th>\n",
              "      <td>104</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alt-after</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anti-after</th>\n",
              "      <td>87</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows Ã— 170310 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              aa  aaa  aaaaaaaab  ...  zzybvuyyao  zzzivafq  zzzvlmcp\n",
              "alt-before     1    0          0  ...           0         0         0\n",
              "anti-before  104   23          1  ...           1         1         0\n",
              "alt-after      0   21          0  ...           0         0         0\n",
              "anti-after    87   10          0  ...           0         0         1\n",
              "\n",
              "[4 rows x 170310 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "8SvRSF6aiEOm",
        "outputId": "1e14ca97-a7ee-4c8d-b3e5-e752ecb65d5e"
      },
      "source": [
        "tdm = data_dtm.transpose()\n",
        "tdm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alt-before</th>\n",
              "      <th>anti-before</th>\n",
              "      <th>alt-after</th>\n",
              "      <th>anti-after</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>aa</th>\n",
              "      <td>1</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aaa</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>21</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aaaaaaaab</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aaaaaaand</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aaaaand</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           alt-before  anti-before  alt-after  anti-after\n",
              "aa                  1          104          0          87\n",
              "aaa                 0           23         21          10\n",
              "aaaaaaaab           0            1          0           0\n",
              "aaaaaaand           0            1          0           0\n",
              "aaaaand             0            0          0           1"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27qyVxKFiFw3"
      },
      "source": [
        "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
        "corpus = matutils.Sparse2Corpus(sparse_counts)\n",
        "\n",
        "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nj_ewcdiHHu",
        "outputId": "dd1547bd-ad41-476e-a2e2-0c835c3ec721"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=20)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.016*\"covid\" + 0.014*\"vaccin\" + 0.013*\"la\" + 0.009*\"en\" + 0.009*\"el\" + 0.008*\"que\" + 0.005*\"lo\" + 0.004*\"peopl\" + 0.004*\"se\" + 0.004*\"health\"\n",
            "Topic: 1 \n",
            "Words: 0.021*\"vaccin\" + 0.005*\"health\" + 0.004*\"peopl\" + 0.004*\"children\" + 0.004*\"state\" + 0.003*\"time\" + 0.003*\"year\" + 0.003*\"truth\" + 0.003*\"govern\" + 0.003*\"said\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AahjkdVg4t3B",
        "outputId": "8fc2b631-5327-4556-fe33-894b847e7897"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=20)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.023*\"vaccin\" + 0.005*\"health\" + 0.004*\"children\" + 0.004*\"peopl\" + 0.004*\"state\" + 0.004*\"truth\" + 0.003*\"time\" + 0.003*\"year\" + 0.003*\"govern\" + 0.003*\"freedom\"\n",
            "Topic: 1 \n",
            "Words: 0.016*\"covid\" + 0.013*\"vaccin\" + 0.013*\"la\" + 0.008*\"en\" + 0.008*\"el\" + 0.008*\"que\" + 0.005*\"lo\" + 0.004*\"peopl\" + 0.004*\"se\" + 0.004*\"health\"\n",
            "Topic: 2 \n",
            "Words: 0.001*\"vaccin\" + 0.001*\"covid\" + 0.001*\"el\" + 0.001*\"la\" + 0.001*\"en\" + 0.000*\"que\" + 0.000*\"lo\" + 0.000*\"peopl\" + 0.000*\"health\" + 0.000*\"por\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqDB7SkD4w8F",
        "outputId": "3d1674fe-d2e4-4d6d-ad63-e14a638f32ac"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=20)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.028*\"vaccin\" + 0.005*\"health\" + 0.005*\"children\" + 0.004*\"peopl\" + 0.004*\"time\" + 0.004*\"state\" + 0.003*\"truth\" + 0.003*\"year\" + 0.003*\"parent\" + 0.003*\"medic\"\n",
            "Topic: 1 \n",
            "Words: 0.017*\"covid\" + 0.014*\"vaccin\" + 0.014*\"la\" + 0.009*\"en\" + 0.009*\"el\" + 0.008*\"que\" + 0.005*\"lo\" + 0.004*\"peopl\" + 0.004*\"se\" + 0.004*\"health\"\n",
            "Topic: 2 \n",
            "Words: 0.010*\"podcast\" + 0.006*\"presid\" + 0.006*\"said\" + 0.005*\"conserv\" + 0.005*\"daili\" + 0.005*\"govern\" + 0.005*\"zambia\" + 0.005*\"peopl\" + 0.004*\"covid\" + 0.004*\"trump\"\n",
            "Topic: 3 \n",
            "Words: 0.001*\"vaccin\" + 0.001*\"covid\" + 0.000*\"en\" + 0.000*\"la\" + 0.000*\"el\" + 0.000*\"peopl\" + 0.000*\"que\" + 0.000*\"lo\" + 0.000*\"se\" + 0.000*\"new\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbHI-bt841mI",
        "outputId": "f7f648be-f84b-45c8-a732-c01859deb02f"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=5, passes=20)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.028*\"vaccin\" + 0.005*\"health\" + 0.005*\"children\" + 0.004*\"peopl\" + 0.004*\"time\" + 0.004*\"state\" + 0.003*\"truth\" + 0.003*\"year\" + 0.003*\"parent\" + 0.003*\"medic\"\n",
            "Topic: 1 \n",
            "Words: 0.017*\"covid\" + 0.014*\"vaccin\" + 0.014*\"la\" + 0.009*\"en\" + 0.009*\"el\" + 0.008*\"que\" + 0.005*\"lo\" + 0.004*\"peopl\" + 0.004*\"se\" + 0.004*\"health\"\n",
            "Topic: 2 \n",
            "Words: 0.001*\"vaccin\" + 0.000*\"covid\" + 0.000*\"la\" + 0.000*\"peopl\" + 0.000*\"que\" + 0.000*\"health\" + 0.000*\"el\" + 0.000*\"time\" + 0.000*\"children\" + 0.000*\"truth\"\n",
            "Topic: 3 \n",
            "Words: 0.010*\"podcast\" + 0.006*\"presid\" + 0.006*\"said\" + 0.005*\"conserv\" + 0.005*\"daili\" + 0.005*\"govern\" + 0.005*\"zambia\" + 0.005*\"peopl\" + 0.004*\"covid\" + 0.004*\"trump\"\n",
            "Topic: 4 \n",
            "Words: 0.001*\"vaccin\" + 0.001*\"covid\" + 0.001*\"la\" + 0.001*\"el\" + 0.001*\"que\" + 0.000*\"en\" + 0.000*\"se\" + 0.000*\"lo\" + 0.000*\"del\" + 0.000*\"peopl\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnE0VWmkiIWd",
        "outputId": "22e411ae-4f47-4f37-c60b-8a0acdeaa99a"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=80)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.021*\"vaccin\" + 0.005*\"health\" + 0.004*\"peopl\" + 0.004*\"children\" + 0.004*\"state\" + 0.003*\"time\" + 0.003*\"year\" + 0.003*\"truth\" + 0.003*\"govern\" + 0.003*\"said\"\n",
            "Topic: 1 \n",
            "Words: 0.016*\"covid\" + 0.014*\"vaccin\" + 0.013*\"la\" + 0.009*\"en\" + 0.009*\"el\" + 0.008*\"que\" + 0.005*\"lo\" + 0.004*\"peopl\" + 0.004*\"se\" + 0.004*\"health\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVTQqw5146nn",
        "outputId": "372eeee7-6491-4461-8d57-bae324f873f3"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=80)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.016*\"covid\" + 0.014*\"vaccin\" + 0.014*\"la\" + 0.009*\"en\" + 0.009*\"el\" + 0.008*\"que\" + 0.005*\"lo\" + 0.004*\"peopl\" + 0.004*\"se\" + 0.004*\"health\"\n",
            "Topic: 1 \n",
            "Words: 0.010*\"podcast\" + 0.006*\"presid\" + 0.005*\"said\" + 0.005*\"conserv\" + 0.005*\"daili\" + 0.005*\"govern\" + 0.005*\"zambia\" + 0.004*\"peopl\" + 0.004*\"covid\" + 0.004*\"trump\"\n",
            "Topic: 2 \n",
            "Words: 0.027*\"vaccin\" + 0.005*\"health\" + 0.005*\"children\" + 0.004*\"peopl\" + 0.004*\"time\" + 0.004*\"state\" + 0.003*\"truth\" + 0.003*\"year\" + 0.003*\"parent\" + 0.003*\"medic\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO5P4GE649Bs",
        "outputId": "122b3018-ffe0-4a4e-f6b2-466039e90e30"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=80)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.000*\"vaccin\" + 0.000*\"la\" + 0.000*\"covid\" + 0.000*\"en\" + 0.000*\"peopl\" + 0.000*\"health\" + 0.000*\"time\" + 0.000*\"el\" + 0.000*\"govern\" + 0.000*\"news\"\n",
            "Topic: 1 \n",
            "Words: 0.028*\"vaccin\" + 0.005*\"health\" + 0.005*\"children\" + 0.004*\"peopl\" + 0.004*\"time\" + 0.004*\"state\" + 0.003*\"truth\" + 0.003*\"year\" + 0.003*\"parent\" + 0.003*\"medic\"\n",
            "Topic: 2 \n",
            "Words: 0.010*\"podcast\" + 0.006*\"presid\" + 0.006*\"said\" + 0.005*\"conserv\" + 0.005*\"daili\" + 0.005*\"govern\" + 0.005*\"zambia\" + 0.005*\"peopl\" + 0.004*\"covid\" + 0.004*\"trump\"\n",
            "Topic: 3 \n",
            "Words: 0.017*\"covid\" + 0.014*\"vaccin\" + 0.014*\"la\" + 0.009*\"en\" + 0.009*\"el\" + 0.008*\"que\" + 0.005*\"lo\" + 0.004*\"peopl\" + 0.004*\"se\" + 0.004*\"health\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTARBrng4_cw",
        "outputId": "d80bb250-1847-4fe2-8bb8-4698e92a269a"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=5, passes=80)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.010*\"podcast\" + 0.006*\"presid\" + 0.006*\"said\" + 0.005*\"conserv\" + 0.005*\"daili\" + 0.005*\"govern\" + 0.005*\"zambia\" + 0.005*\"peopl\" + 0.004*\"covid\" + 0.004*\"trump\"\n",
            "Topic: 1 \n",
            "Words: 0.000*\"vaccin\" + 0.000*\"peopl\" + 0.000*\"covid\" + 0.000*\"govern\" + 0.000*\"la\" + 0.000*\"health\" + 0.000*\"truth\" + 0.000*\"said\" + 0.000*\"time\" + 0.000*\"year\"\n",
            "Topic: 2 \n",
            "Words: 0.000*\"vaccin\" + 0.000*\"covid\" + 0.000*\"la\" + 0.000*\"que\" + 0.000*\"en\" + 0.000*\"el\" + 0.000*\"peopl\" + 0.000*\"lo\" + 0.000*\"health\" + 0.000*\"se\"\n",
            "Topic: 3 \n",
            "Words: 0.028*\"vaccin\" + 0.005*\"health\" + 0.005*\"children\" + 0.004*\"peopl\" + 0.004*\"time\" + 0.004*\"state\" + 0.003*\"truth\" + 0.003*\"year\" + 0.003*\"parent\" + 0.003*\"medic\"\n",
            "Topic: 4 \n",
            "Words: 0.017*\"covid\" + 0.014*\"vaccin\" + 0.014*\"la\" + 0.009*\"en\" + 0.009*\"el\" + 0.008*\"que\" + 0.005*\"lo\" + 0.004*\"peopl\" + 0.004*\"se\" + 0.004*\"health\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZQax9DQ9oyT"
      },
      "source": [
        "import pickle\n",
        "outfile = open(\"cleaned_text\",'wb')\n",
        "pickle.dump(data_df,outfile)\n",
        "outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy8CvOE4bjHl",
        "outputId": "68b52fd2-4803-4028-e234-46a71fbdd921"
      },
      "source": [
        "for t in corpus_transformed:\n",
        "  print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.20086189), (1, 0.7991381)]\n",
            "[(1, 0.9996052)]\n",
            "[(0, 0.9497707), (1, 0.050229285)]\n",
            "[(0, 0.99401087)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxx4vTD4fKYT"
      },
      "source": [
        "ct = []\n",
        "for t in corpus_transformed:\n",
        "  for (a,b) in t:\n",
        "    if b>0.7:\n",
        "      ct +=[(a,b)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62zURQZ3bpNB"
      },
      "source": [
        "Take Nouns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAklkS5jbolg",
        "outputId": "5ceb3126-aae7-4f89-d465-9e68c83cce0c"
      },
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def nouns(text):\n",
        "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
        "    is_noun = lambda pos: pos[:2] == 'NN'\n",
        "    tokenized = word_tokenize(text)\n",
        "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
        "    return ' '.join(all_nouns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "DCwc7h1Ubu43",
        "outputId": "edd84cba-8f84-4ef8-c127-8bdb6f4d78ea"
      },
      "source": [
        "data_clean = pd.read_pickle('cleaned_text')\n",
        "data_clean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>alt-before</th>\n",
              "      <td>happi birthday madelein carrol highest paid ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anti-before</th>\n",
              "      <td>realli gonna kill everybodi dmt spiritu scienc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alt-after</th>\n",
              "      <td>classifi testimoni opposit biden surrend under...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anti-after</th>\n",
              "      <td>see break fda panel overwhelmingli reject pfiz...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                          text\n",
              "alt-before   happi birthday madelein carrol highest paid ac...\n",
              "anti-before  realli gonna kill everybodi dmt spiritu scienc...\n",
              "alt-after    classifi testimoni opposit biden surrend under...\n",
              "anti-after   see break fda panel overwhelmingli reject pfiz..."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttPI884EcA5h",
        "outputId": "d6be152a-46cf-4b32-a019-acabf72dab06"
      },
      "source": [
        "data_nouns = data_clean.text.apply(nouns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt-before     happi birthday actress world ww receiv preside...\n",
              "anti-before    realli gon dmt spiritu scienc travers feat min...\n",
              "alt-after      classifi testimoni opposit surrend underscor m...\n",
              "anti-after     panel overwhelmingli pfizer booster issu boost...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "a3ARZtHOfii_",
        "outputId": "377339a7-bc00-4204-fc2a-805eac298f05"
      },
      "source": [
        "data_nouns = pd.DataFrame(data_nouns)\n",
        "data_nouns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>alt-before</th>\n",
              "      <td>happi birthday actress world ww receiv preside...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anti-before</th>\n",
              "      <td>realli gon dmt spiritu scienc travers feat min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alt-after</th>\n",
              "      <td>classifi testimoni opposit surrend underscor m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anti-after</th>\n",
              "      <td>panel overwhelmingli pfizer booster issu boost...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                          text\n",
              "alt-before   happi birthday actress world ww receiv preside...\n",
              "anti-before  realli gon dmt spiritu scienc travers feat min...\n",
              "alt-after    classifi testimoni opposit surrend underscor m...\n",
              "anti-after   panel overwhelmingli pfizer booster issu boost..."
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJp1PVm5dAZ7"
      },
      "source": [
        "from sklearn.feature_extraction import text\n",
        "add_stop_words = ['el', 'la', 'news', 'year', 'vaccine', 'covid', 'people']\n",
        "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
        "\n",
        "cv = CountVectorizer(stop_words=stop_words)\n",
        "data_cv = cv.fit_transform(data_nouns.text)\n",
        "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
        "data_dtm.index = data_nouns.index\n",
        "tdm = data_dtm.transpose()\n",
        "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
        "corpus = matutils.Sparse2Corpus(sparse_counts)\n",
        "\n",
        "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovzS0wRSdKt4",
        "outputId": "3dc0513d-ab17-4b5d-de6a-3a90a2479812"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=20)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.032*\"vaccin\" + 0.008*\"health\" + 0.008*\"children\" + 0.006*\"time\" + 0.005*\"state\" + 0.005*\"peopl\" + 0.005*\"parent\" + 0.005*\"truth\" + 0.004*\"freedom\" + 0.004*\"day\"\n",
            "Topic: 1 \n",
            "Words: 0.012*\"podcast\" + 0.008*\"presid\" + 0.008*\"daili\" + 0.008*\"conserv\" + 0.006*\"zambia\" + 0.006*\"state\" + 0.006*\"nation\" + 0.005*\"peopl\" + 0.005*\"trump\" + 0.005*\"time\"\n",
            "Topic: 2 \n",
            "Words: 0.017*\"vaccin\" + 0.011*\"que\" + 0.006*\"health\" + 0.006*\"peopl\" + 0.004*\"lo\" + 0.004*\"por\" + 0.004*\"state\" + 0.004*\"time\" + 0.004*\"para\" + 0.004*\"coronaviru\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx6fbNd6gA1B",
        "outputId": "d93c80fd-db7f-47ea-80e6-01057395c2e1"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=20)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.005*\"vaccin\" + 0.002*\"health\" + 0.002*\"children\" + 0.001*\"state\" + 0.001*\"truth\" + 0.001*\"time\" + 0.001*\"peopl\" + 0.001*\"doctor\" + 0.001*\"day\" + 0.001*\"freedom\"\n",
            "Topic: 1 \n",
            "Words: 0.013*\"podcast\" + 0.009*\"presid\" + 0.008*\"daili\" + 0.008*\"conserv\" + 0.006*\"zambia\" + 0.006*\"state\" + 0.006*\"nation\" + 0.005*\"peopl\" + 0.005*\"trump\" + 0.005*\"time\"\n",
            "Topic: 2 \n",
            "Words: 0.032*\"vaccin\" + 0.008*\"health\" + 0.008*\"children\" + 0.006*\"time\" + 0.006*\"state\" + 0.005*\"peopl\" + 0.005*\"parent\" + 0.005*\"truth\" + 0.004*\"freedom\" + 0.004*\"day\"\n",
            "Topic: 3 \n",
            "Words: 0.017*\"vaccin\" + 0.011*\"que\" + 0.006*\"health\" + 0.006*\"peopl\" + 0.004*\"lo\" + 0.004*\"por\" + 0.004*\"state\" + 0.004*\"time\" + 0.004*\"para\" + 0.004*\"coronaviru\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ducThxhmgCne",
        "outputId": "19a024d6-c428-456b-96b1-c2668ea75295"
      },
      "source": [
        "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=80)\n",
        "for idx, topic in lda.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.017*\"vaccin\" + 0.011*\"que\" + 0.006*\"health\" + 0.006*\"peopl\" + 0.004*\"lo\" + 0.004*\"por\" + 0.004*\"state\" + 0.004*\"time\" + 0.004*\"para\" + 0.004*\"coronaviru\"\n",
            "Topic: 1 \n",
            "Words: 0.013*\"podcast\" + 0.009*\"presid\" + 0.008*\"daili\" + 0.008*\"conserv\" + 0.006*\"zambia\" + 0.006*\"state\" + 0.006*\"nation\" + 0.005*\"peopl\" + 0.005*\"trump\" + 0.005*\"time\"\n",
            "Topic: 2 \n",
            "Words: 0.032*\"vaccin\" + 0.008*\"health\" + 0.008*\"children\" + 0.006*\"time\" + 0.006*\"state\" + 0.005*\"peopl\" + 0.005*\"parent\" + 0.005*\"truth\" + 0.004*\"freedom\" + 0.004*\"day\"\n",
            "Topic: 3 \n",
            "Words: 0.000*\"vaccin\" + 0.000*\"peopl\" + 0.000*\"que\" + 0.000*\"health\" + 0.000*\"state\" + 0.000*\"children\" + 0.000*\"case\" + 0.000*\"report\" + 0.000*\"time\" + 0.000*\"world\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLSGnbyPlih3"
      },
      "source": [
        "topic 0: \n",
        "topic 1: political\n",
        "topic 2: free will"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skXuAGqddTYd",
        "outputId": "8ed7eae5-af53-477d-b115-7e5f37e76f9f"
      },
      "source": [
        "corpus_transformed = lda[corpus]\n",
        "for t in corpus_transformed:\n",
        "  print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 0.9699018), (2, 0.030094396)]\n",
            "[(2, 0.9997456)]\n",
            "[(1, 0.9997837)]\n",
            "[(0, 0.9946027)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB7A9Zyvlb8L"
      },
      "source": [
        "ct = []\n",
        "for t in corpus_transformed:\n",
        "  for (a,b) in t:\n",
        "    if b>0.7:\n",
        "      ct +=[(a,b)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3u-ixDPiKYa",
        "outputId": "408f1db9-84fc-4404-d4f8-e37ddde586c0"
      },
      "source": [
        "list(zip([a for (a,b) in ct], data_dtm.index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 'alt-before'), (2, 'anti-before'), (1, 'alt-after'), (0, 'anti-after')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}